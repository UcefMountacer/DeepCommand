# -*- coding: utf-8 -*-
"""keras_on_signal_features.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eg4H7jUJ-8E_rusNZoXs0FOw9Afsg9ro
"""

import tensorflow as tf
import keras
import numpy as np
import pandas as pd
from sklearn import preprocessing
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasClassifier
from keras.utils import np_utils
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline
import math
from keras import layers
from sklearn.model_selection import train_test_split

data = pd.read_csv('data.csv')
#data = dataf.drop(['Unnamed: 0'], axis = 1)
#data.head()
data.head()

columns = ['max_stft','min_stft','std_stft','amp_stft','mean_stft',
              'max_cqt','min_cqt','std_cqt','amp_cqt','mean_cqt',
              'max_cens','min_cens','std_cens','amp_cens','mean_cens',
              'max_mfcc','min_mfcc','std_mfcc','amp_mfcc','mean_mfcc',
              'max_rms','min_rms','std_rms','amp_rms','mean_rms',
              'max_centroid','min_centroid','std_centroid','amp_centroid','mean_centroid',
              'max_bandwidth','min_bandwidth','std_bandwidth','amp_bandwidth','mean_bandwidth',
              'max_contrast','min_contrast','std_contrast','amp_contrast','mean_contrast',
              'max_rolloff','min_rolloff','std_rolloff','amp_rolloff','mean_rolloff',
              'max_poly','min_poly','std_poly','amp_poly','mean_poly',
              'max_tonnetz','min_tonnetz','std_tonnetz','amp_tonnetz','mean_tonnetz',
              'max_z_crossing','min_z_crossing','std_z_crossing','amp_z_crossing','mean_z_crossing']
X=data[columns].values
y=data['label'].values
X=preprocessing.StandardScaler().fit(X).transform(X.astype(float))
print(X.shape, y.shape)

# one hot encoding
encoder = LabelEncoder()
encoder.fit(y)
encoded_y = encoder.transform(y)
# convert integers to dummy variables (i.e. one hot encoded)
dummy_y = np_utils.to_categorical(encoded_y)
dummy_y.shape

X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, test_size=0.3)
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

# define baseline model

# create model
model = Sequential()
model.add(Dense(100, activation='relu',kernel_initializer='random_normal', input_dim=60))
#model.add(Dense(100, activation='relu',kernel_initializer='random_normal'))
model.add(Dense(200, activation='relu',kernel_initializer='random_normal'))
model.add(Dense(30, activation='relu',kernel_initializer='random_normal'))
#model.add(Dense(30, activation='relu',kernel_initializer='random_normal'))
model.add(Dense(10, activation='relu',kernel_initializer='random_normal'))
model.add(Dense(4, activation='softmax',kernel_initializer='random_normal'))
# Compile model
model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])

'''
estimator = KerasClassifier(build_fn=baseline_model, epochs=80, batch_size=100, verbose=0)
kfold = KFold(n_splits=4, shuffle=True, random_state=3)
cross_val_score(estimator, X, dummy_y, cv=4)
'''

model.fit(X_train,y_train, batch_size=10, epochs=100)

eval_model=model.evaluate(X_train, y_train)
eval_model

y_pred=model.predict(X_test)
y_pred =(y_pred>0.5)
y_pred

from sklearn.metrics import confusion_matrix
cm = matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))
print(matrix)
import seaborn as sn
sn.heatmap(cm, annot=True)